{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Get Resources\n",
    "This project requires git repos to function.\n"
   ],
   "id": "2293bdb1cbf316c9"
  },
  {
   "cell_type": "code",
   "id": "c1e7863caf638344",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "test = False\n",
    "\n",
    "org = \"kuadrant\"\n",
    "location = Path(\"/tmp/cyclomatic_complexity\")\n",
    "test_repos = [\n",
    "    \"git@github.com:Kuadrant/wasm-shim.git\",\n",
    "    \"git@github.com:Kuadrant/.github.git\",\n",
    "    \"git@github.com:Kuadrant/governance.git\"\n",
    "]\n",
    "\n",
    "repos = []\n",
    "\n",
    "if test: \n",
    "    repos = test_repos\n",
    "else:\n",
    "    url = f\"https://api.github.com/orgs/{org}/repos\"\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"data fetch failed: {resp.status_code}\")\n",
    "        exit(1)\n",
    "    repositories = resp.json()\n",
    "    for repo in repositories:\n",
    "        if repo['private']:\n",
    "            print(f\"Private Repo: {repo['name']}\")\n",
    "            continue\n",
    "        if repo['fork']:\n",
    "            print(f\"Forked Repo: {repo['name']}\")\n",
    "            continue\n",
    "        if repo['archived']:\n",
    "            print(f\"Archived Repo: {repo['name']}\")\n",
    "            continue\n",
    "        repos.append(repo['ssh_url'])\n",
    "    \n",
    "    \n",
    "print(repos)\n",
    "\n",
    "location.mkdir(parents=True, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "40fa157f396295c0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "from time import perf_counter\n",
    "start = perf_counter()\n",
    "for repo in repos:\n",
    "    !git -C {location} clone --single-branch {repo}\n",
    "end = perf_counter()\n",
    "print(f\"Repo cloning took {int(end-start)} seconds\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e8b921fa52f72118",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Baseline data\n",
    "As we want to look at the data over time, we need some method to slice the data up.\n",
    "Release will not work as some projects do not follow a release cycle.\n",
    "This is way the merge commits will be markers that is used set the points in time.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b80510e810d02282",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "import os\n",
    "from cyclomatic_complexity import list_to_columns\n",
    "projects = None\n",
    "for _, dirs, _ in os.walk(location):\n",
    "    projects = dirs\n",
    "    break\n",
    "print(f\"Projects: {len(projects)}\")\n",
    "print(list_to_columns(sorted(projects)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dae1849ba5804a62",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "from datetime import datetime\n",
    "data = {}\n",
    "linfo = []\n",
    "total = 0\n",
    "for project in projects:\n",
    "    if project not in data:\n",
    "        data.setdefault(project, [])\n",
    "    merge_log = !git -C {Path(location, project)} log --merges --pretty=format:'%H ||| %ad'\n",
    "    last_merge = None\n",
    "    for log in merge_log:\n",
    "        log = log.split(\"|||\")\n",
    "        data[project].append({\"commit\": log[0].strip(), \"timestamp\": log[1].strip()})\n",
    "        if last_merge is None:\n",
    "            last_merge = log[0].strip()\n",
    "\n",
    "\n",
    "    commit_log = []\n",
    "    if last_merge is not None:\n",
    "        last_merge_time = !git -C {Path(location, project)} show -s --format='%at' {last_merge}\n",
    "        last_merge_time = last_merge_time[0]\n",
    "        commit_log = !git -C {Path(location, project)} log --author-date-order --all --after={last_merge_time} --pretty=format:'%H ||| %ad'    \n",
    "\n",
    "    for i in range(len(commit_log) - 1):\n",
    "        log = commit_log[i]\n",
    "        log = log.split(\"|||\")\n",
    "        data[project].append({\"commit\": log[0].strip(), \"timestamp\": log[1].strip()})\n",
    "\n",
    "    data[project] = sorted(data[project], key=lambda t: datetime.strptime(t['timestamp'], \"%a %b %d %H:%M:%S %Y %z\"))\n",
    "\n",
    "    total += len(data[project])\n",
    "    linfo.append(f\"{project}: {len(data[project])}\")\n",
    "\n",
    "print(f\"Merges: {total}\")\n",
    "print(list_to_columns(sorted(linfo)))        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ae1ec3c18a5dae98",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "id": "ebede349f275c4c3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "exclude_dir = {\n",
    "    \"kuadrant.github.io\": [\n",
    "        Path('static'),\n",
    "        Path('_site'),\n",
    "    ],\n",
    "    \"wasm-shim\": [\n",
    "        Path('src', 'envoy_ext_auth'), # Seems to be only in the initial merges and trows graphs\n",
    "    ],\n",
    "    \"kuadrant-operator\": [\n",
    "        Path('vendor'),\n",
    "    ],\n",
    "    \"authorino\": [\n",
    "        Path('vendor'),\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "cc_exclude_dir = {\n",
    "    \"kuadrant.github.io\": [\n",
    "        Path('static', 'vendor'),\n",
    "        Path('static', 'js'),\n",
    "        Path('_site', 'static'),\n",
    "        Path('_site', 'static', 'vendor'),\n",
    "    ],\n",
    "    \"wasm-shim\": [\n",
    "        Path('src', 'envoy_ext_auth'), # Seems to be only in the initial merges and trows graphs\n",
    "    ],\n",
    "    \"kuadrant-operator\": [\n",
    "        Path('vendor'),\n",
    "    ],\n",
    "    \"authorino\": [\n",
    "        Path('vendor'),\n",
    "    ]\n",
    "}\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4682960b3c6af3bd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## LOC Lines Of Code\n",
    "As we are looking at the projects over time we need to know how much the projects have grown. For this we will use the lines of Code, LOC, as the measurement tool."
   ]
  },
  {
   "cell_type": "code",
   "id": "b53f9815e5df715f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "import json\n",
    "def get_loc(scan_path, exclude: list[Path]):\n",
    "    dirs = ''\n",
    "    if exclude:\n",
    "        dirs = []\n",
    "        for e in exclude:\n",
    "            path = Path(scan_path, e)\n",
    "            if path.is_dir():\n",
    "                dirs.append(str(e))\n",
    "        dirs = ','.join(dirs)        \n",
    "        \n",
    "    out = !scc -z --format=json --exclude-dir={dirs} {scan_path} \n",
    "    return json.loads(out[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12e5da0b87cff6ed",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Cyclomatic Complexity\n",
    "Each language has their own sets of tools to get the score. Bellow is the list of tools used for the different languages.\n",
    "\n",
    "* go --> [gocyclo](https://github.com/fzipp/gocyclo)\n",
    "* rust --> [rust-code-analysis-cli](https://github.com/mozilla/rust-code-analysis)\n",
    "* python --> [rust-code-analysis-cli](https://github.com/mozilla/rust-code-analysis)\n",
    "* JavaScript --> [rust-code-analysis-cli](https://github.com/mozilla/rust-code-analysis)\n",
    "* Ruby --> [RuboCop](https://rubocop.org/)\n",
    "\n",
    "Result structure\n",
    "```pythoN\n",
    "cc = {\n",
    "    'sorce': 1,\n",
    "    'function': 'function_name',\n",
    "    'file': 'path/to/file'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "7f248ad662f8a697",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def unknown(root, exclude: list[Path]):\n",
    "    \"\"\"Default function for language without a tool defined.\"\"\"\n",
    "    return None\n",
    "\n",
    "def gocyclo(root, exclude: list[Path]):\n",
    "    \"\"\"\n",
    "    ['1', 'v1beta1', '(*RateLimitPolicy).DeepCopyInto', '/tmp/cyclomatic_complexity/kuadrant-operator/api/v1beta1/zz_generated.deepcopy.go:502:1']\n",
    "    \"\"\"\n",
    "    print(\"Getting Cyclomatic Complexity values for Go files\")\n",
    "    out =  []\n",
    "    result = !gocyclo {root} \n",
    "    for row in result:\n",
    "        row = row.split()\n",
    "        tmp = {'score': int(row[0]), 'function': row[2], 'file': row[3].split(':')[0]}\n",
    "        if 'zz_generated.deepcopy.go' in tmp['file']:\n",
    "            continue\n",
    "        out.append(tmp)\n",
    "        \n",
    "    return out\n",
    "   \n",
    "def rust_code_analysis_cli(root, exclude: list[Path]):\n",
    "    print(\"Getting Cyclomatic Complexity with rust-code-analysis-cli\")\n",
    "    dirs = ''\n",
    "    if exclude:\n",
    "        dirs = []\n",
    "        for e in exclude:\n",
    "            path = Path(root, e)\n",
    "            if path.is_dir():\n",
    "                for root, _, _ in os.walk(path):\n",
    "                    dirs.append(str(Path(root, '*')))  \n",
    "                    \n",
    "                dirs.append(str(Path(path, '*')))\n",
    "        dirs = ' '.join([\"--exclude \" + p for p in dirs])\n",
    "    d = !rust-code-analysis-cli --paths {root} --metrics --output-format json {dirs}\n",
    "    \n",
    "    files = []\n",
    "    for i in d:\n",
    "        i = json.loads(i)\n",
    "        files.append(i)\n",
    "    out = []\n",
    "    def get_data(object):\n",
    "        for space in object['spaces']:\n",
    "            if space['kind'] == \"function\":\n",
    "                out.append({'file': file_name, 'function': space['name'], 'score': space['metrics']['cyclomatic']['sum']})\n",
    "            else:\n",
    "                get_data(space)\n",
    "    for f in files:\n",
    "        file_name = f['name']\n",
    "        get_data(f)\n",
    "    return out\n",
    "\n",
    "def rubocop(root, exclude: list[Path]):\n",
    "    print(\"Running RuboCop\")\n",
    "    p = Path(root)\n",
    "    parent = p.parent\n",
    "    config_file = Path(parent, \".rubocop.yml\")\n",
    "    if not config_file.exists():\n",
    "        config = \"\"\"# The behavior of RuboCop can be controlled via the .rubocop.yml\n",
    "# configuration file. It makes it possible to enable/disable\n",
    "# certain cops (checks) and to alter their behavior if they accept\n",
    "# any parameters. The file can be placed either in your home\n",
    "# directory or in some project directory.\n",
    "#\n",
    "# RuboCop will start looking for the configuration file in the directory\n",
    "# where the inspected file is and continue its way up to the root directory.\n",
    "#\n",
    "# See https://docs.rubocop.org/rubocop/configuration\n",
    "\n",
    "AllCops:\n",
    "  DisabledByDefault: true\n",
    "\n",
    "Metrics/CyclomaticComplexity:\n",
    "  Enabled: true\n",
    "  Max: 0       \n",
    "        \"\"\"\n",
    "        config_file.write_text(config)\n",
    "        \n",
    "    result = !rubocop -c {config_file} --format=json {root}\n",
    "    \n",
    "    result = result[0]\n",
    "    result = json.loads(result)\n",
    "    out = []\n",
    "    for f in result['files']:\n",
    "        file_name = f['path']\n",
    "        for offense in f['offenses']:\n",
    "            score = offense['message'].split('[')[1].split('/')[0]\n",
    "            try:\n",
    "                score = int(score)\n",
    "            except ValueError:\n",
    "                print(f\"\\n\\n{root=}\\n{score=}\\n\\n\")\n",
    "                continue\n",
    "            name = f\"start_line:{offense['location']['start_line']}\"\n",
    "            out.append({'file': file_name, 'function': name, 'score': score})\n",
    "    \n",
    "    return out\n",
    "    \n",
    "def get_cc_tool(langauge: str):\n",
    "    cc = {\n",
    "        'go': gocyclo,\n",
    "        'rust': rust_code_analysis_cli,\n",
    "        'python': rust_code_analysis_cli,\n",
    "        'javascript': rust_code_analysis_cli,\n",
    "        'ruby': rubocop,\n",
    "        'default': unknown\n",
    "    }\n",
    "    \n",
    "    return cc.get(langauge.lower(), unknown)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a24ad3bffc4896fb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Per commit actions\n",
    "Sadly we need to check out each commit in the merge history in order to be able to run the required data collections. \n",
    "\n",
    "This will take some time to run."
   ]
  },
  {
   "cell_type": "code",
   "id": "a1c65a1198f2e4a2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "from time import perf_counter\n",
    "import json\n",
    "# guide: takes about .6 seconds per commit\n",
    "\n",
    "def can_scan(langauge: str):\n",
    "    disallowed = (\"(gen)\", \"(min)\")\n",
    "    for block in disallowed:\n",
    "        if block in langauge:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "start = perf_counter()\n",
    "for project in projects:\n",
    "    !git -C {ploc} stash\n",
    "    ploc = Path(location, project)\n",
    "    current_HEAD = !git -C {ploc} rev-parse --abbrev-ref HEAD\n",
    "    current_HEAD = current_HEAD[0]\n",
    "    print(f\"{project}: {current_HEAD=}\")\n",
    "    \n",
    "    for entry in data[project]:\n",
    "\n",
    "        !git -C {ploc} checkout {entry['commit']}\n",
    "        print(\"Getting lines of Code data\")\n",
    "        exclude = exclude_dir.get(project, [])\n",
    "        \n",
    "        entry['scc'] = get_loc(ploc, exclude)\n",
    "        entry.setdefault('cc', [])\n",
    "        for lang in  entry['scc']:\n",
    "            if not can_scan(lang['Name']):\n",
    "                continue\n",
    "            action = get_cc_tool(lang['Name'])\n",
    "            result = action(ploc, cc_exclude_dir.get(project, []))\n",
    "            if result is None:\n",
    "                continue\n",
    "            entry['cc'] += result\n",
    "\n",
    "        # insure entries are only counter once\n",
    "        tmp_set = {json.dumps(i) for i in entry['cc']}\n",
    "        entry['cc'] = [json.loads(i) for i in tmp_set]\n",
    "        \n",
    "        !git -C {ploc} stash\n",
    "    !git -C {ploc} checkout {current_HEAD}    \n",
    "end = perf_counter()\n",
    "\n",
    "print(f\"Code Analysis took {int(end - start)} seconds\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a976b19e4b25769b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\n",
    "# Save data\n",
    "The data is saved for analysis later"
   ]
  },
  {
   "cell_type": "code",
   "id": "95aeb7b7bda189a3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "data_route = Path(\"../data\")\n",
    "data_route.mkdir(parents=True, exist_ok=True)\n",
    "data_file = Path(data_route, f'{datetime.now().strftime(\"%Y%m%d-%H%M\")}.json')\n",
    "with open(data_file, 'w') as outfile:\n",
    "    outfile.write(json.dumps(data, indent=4))\n",
    "    print(f\"Data File: {data_file}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
